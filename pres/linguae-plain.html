<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Consolidating linguistic tendencies at the level of individuals and populations for Zipf’s Law of Abbreviation</title>
    <meta charset="utf-8" />
    <meta name="author" content="Thomas Brochhagen" />
    <link href="linguae-plain_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="linguae-plain_files/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, title-slide, title-slide

# Consolidating linguistic tendencies at the level of individuals and populations for Zipf’s Law of Abbreviation
### Thomas Brochhagen
### LINGUAE, 29/04/2021

---





# Background

.large[
* Zipf's Law of Abbreviation: frequent forms are shorter

* Inverse relationship between *use* and *linguistic reduction*

* Kanwal et al. (2017): study what drives this relationship &lt;br&gt;by controlling for communicative pressures
]
---

# Background 

.large[
Zipf's Law of Abbreviation: frequent forms are shorter &lt;br&gt;**at the level of languages**
]

.footnote[
***
Zipf (1935): [The Psycho-Biology of Language]()&lt;br&gt;&lt;br&gt;
Sigurd et al. (2004): [Word length, sentence length and frequency – Zipf revisited]()&lt;br&gt;&lt;br&gt;
Piantadosi et al. (2011): [Word lengths are optimized for efficient communication]()&lt;br&gt;&lt;br&gt;
Ferrer-i-Cancho et al. (2013): [Compression as a Universal Principle of Animal Behavior]()&lt;br&gt;&lt;br&gt;
...
]


---

# Background 

.large[
Inverse relationship between *use* and *linguistic reduction*
&lt;br&gt; **across strata**
]

.footnote[
***
Clark &amp; Wilkes-Gibbs (1986): [Referring as a collaborative process]()&lt;br&gt;&lt;br&gt;
Kim et al. (2011): [Phonetic convergence in spontaneous conversations as a function of interlocutor language distance]()&lt;br&gt;&lt;br&gt;
Pickering &amp; Ferreira (2008):  [Structural priming:  A critical review]()&lt;br&gt;&lt;br&gt;
Hawkins et al (2017): [Convention-formation in iterated reference games]()&lt;br&gt;&lt;br&gt;
...
]

---

# Background 

.large[
Kanwal et al. (2017) study what drives the relationship between&lt;br&gt; frequency and form by controlling for communicative pressures&lt;br&gt; **at the level of dyads**
]

.footnote[
***
Kanwal et al. (2017): [Zipf’s Law of Abbreviation and the Principle of Least Effort: Language users optimise a miniature lexicon for efficient communication](). *Cognition*
]

---

# The study I'll build on today 
Modest re-analysis of Kanwal et al. (2017) to
  * explicitly model subjects' behavior
  
  * gain insight into how population-level, dyadic-level and individual-level relate to each other; and how to possibly begin to link them
&lt;br&gt;&lt;br&gt;
&lt;br&gt;&lt;br&gt;
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;


.footnote[
***
Brochhagen (2021): [Brief at the risk of being misunderstood: Consolidating population- and individual-level tendencies](http://brochhagen.github.io/brochhagen.github.io/content/ms/accepted-manuscript-cobb.pdf). *Computational Brain &amp; Behavior*
]

---

class: center

# Experimental setup
Kanwal et al. (2017) condition 4

---

## Training (miniature lexicon acquisition)
&lt;img src="./artificial-language-cropped.jpg" width="80%" style="display: block; margin: auto;" /&gt;


---
# Testing (condition 4) 

* Pair subjects and let them interact for 62 trials&lt;br&gt;&lt;br&gt;32 sender trials, 32 receiver trials (alternating)&lt;br&gt;&lt;br&gt;

* Same object frequencies as in training&lt;br&gt;&lt;br&gt;

* Message transmission time is proportional to message length&lt;br&gt; `\(\rightarrow\)` Sending ambiguous *zop* takes `\(\frac{3}{7}\)` of the time of alternatives &lt;br&gt;&lt;br&gt;

* The fastest &amp; most accurate pairs win a prize&lt;br&gt; `\(\rightarrow\)` Pressure to use short form if you believe your interlocutor will get it

---

# Kanwal et al's analysis

* Logistic regression with short name as binary response&lt;br&gt;&lt;br&gt;

* Object frequency (frequent/infrequent), trial number, and their interaction as fixed effects&lt;br&gt;&lt;br&gt;

* By-participant intercepts and slopes as random effects for object frequency and trial number&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

**Finding:** Positive effect of trial number on short form use only for frequent object&lt;br&gt;&lt;br&gt;

---

# Some open questions

1. How did individual speakers behave?&lt;br&gt;&lt;br&gt;
  * Change over time
  * On what strategies did they converge&lt;br&gt;&lt;br&gt;
2. How did their behavior compare to that of their partners?&lt;br&gt;&lt;br&gt;
3. How do population-level predictions compare to (1) and (2)?&lt;br&gt;&lt;br&gt;
4. How can we relate trends from individuals and dyads to a community of speakers?

---

# Some model desiderata

* Accommodate for multiple association patterns (cf. Parikh 2000)

* Accommodate for signaling behavior that can change as a function of interlocutor's behavior

.footnote[
***
Parikh (2000): [Communication, Meaning, and Interpretation]()&lt;br&gt;&lt;br&gt;
Brochhagen (2017): [ Signalling under Uncertainty: Interpretative Alignment without a Common Prior ]()&lt;br&gt;&lt;br&gt;
Hawkins et al (2017): [Convention-formation in iterated reference games]()


]

---

class: center

# Speaker model

.footnote[
***
We return to model identifiability between Brochhagen (2017) and Hawkins et al. (2017) at the end

]


---
## Intuitions

* RSA-style choice functions (*soft-max*; *Luce's rule*; *rationality parameter*)
&lt;br&gt;&lt;br&gt;"If I believe you expect one object over the other (by a large enough margin) I will use the ambiguous but preferred form to convey that object. Otherwise, I'll play it safe."&lt;br&gt;&lt;br&gt;


* Players can change beliefs over time, based on past success/failure using an ambiguous form&lt;br&gt;&lt;br&gt;"You interpreted my use of an ambiguous form in a certain way before. Consequently, I believe you expected this object (and therefore I will be more likely to signal this object with this expression later)"

---
## Parameters to estimate from the data

.left-column[
&lt;br&gt;
`\(\lambda\)`
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
`\(pr \sim P\)`&lt;br&gt;&lt;br&gt;
`\(P= \text{Beta}(\alpha,\beta)\)`
]

.right-column[
usual soft-maximization parameter, `\(\lambda \geq 0\)`
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
less usual beliefs over (non-common) prior
]


---


## Latent beliefs over expectations

&lt;img src="./uncertainty-sketch-cropped.jpg" width="100%" style="display: block; margin: auto;" /&gt;


---

## The full speaker model
&lt;br&gt;&lt;br&gt;
`\begin{align}
\rho(r \mid m;pr) &amp;\propto L(r,m) \; pr(r),\\
\sigma(m \mid r;P) &amp;\propto \text{exp}(\lambda((\int P(\theta)\rho(r \mid m; \theta)d\theta)-c(m))) 
\end{align}`
&lt;br&gt;
and
`\begin{align}
P_{t+1}(pr \mid w(r);m) \propto (\sum_{r' \in w(r)}\rho(r' \mid m;pr)P_t(pr)),
\end{align}`
with `\(w(r) = \{r\}\)` if the interaction was successful and `\(R \setminus \{r\}\)` otherwise.



---


## Parameters to estimate from the data

.left-column[
&lt;br&gt;
`\(\lambda\)`
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
`\(P= \text{Beta}(\alpha,\beta)\)`
]

.right-column[
soft-maximization parameter, `\(\lambda \geq 0\)`
&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;
beliefs over (non-common) prior
]

---

class: center

# Models

---

  # Overview
| Model        | Population parameters          | Individual parameters  |
|---------------|:-------------:|:------:|
| NoPool      | -- | `\(\lambda_i, \alpha_i, \beta_i\)` |
| FullPool `\(\lambda,\alpha, \beta\)`      | `\(\alpha,\lambda, \beta\)` |   -- |
| FullPool `\(\lambda\)` | `\(\lambda\)`      |  `\(\alpha_i, \beta_i\)` |
| HM `\(\lambda\)`      | `\(\mu_\lambda\)` | `\(\lambda_i \sim N(\mu_\lambda,2)\)` &lt;br&gt; `\(\alpha_i, \beta_i\)` |
| HM `\(\lambda, \alpha, \beta\)`      | `\(\mu_\lambda, \mu_\alpha, \mu_\beta\)` | `\(\lambda_i \sim N(\mu_\lambda,2),\)` &lt;br&gt; `\(\alpha_i \sim N(\mu_\alpha,2)\)` &lt;br&gt; `\(\beta_i \sim N(\mu_\beta,2)\)` |

---

class: center

# Results


.footnote[
***
All models were diagnosed to rule out pathologies, and cross-validated.
]

---



  ## Model comparison (full dataset)
|         | ELPD diff (SE)          | ELPD (SE)  |  
|---------------|:-------------:|:------:|
| HM `\(\lambda, \alpha, \beta\)`      |  0.00 (0.00) | -471.63 (18.74) |  
| HM `\(\lambda\)`      |  -38.16 (5.74) | -509.79 (18.24) | 
| FullPool `\(\lambda,\alpha, \beta\)`      |  -148.24 (12.17) | -619.88 (22.23) | 
| FullPool `\(\lambda\)` |  -154.21 (11.61) | -625.84 (21.24) | 
| NoPool      | -201.02 (34.55) | -672.65 (51.02) | 

&lt;br&gt;&lt;br&gt;

**Finding** The best model, `\(HM_{\lambda,\alpha,\beta}\)`, is ranked first, also across other data subsets and when splitting dyads up

---

## Population-level estimates

&lt;img src="./pop-parameters.png" width="110%" style="display: block; margin: auto;" /&gt;

---
## Individual-level estimates

&lt;img src="./indiv-parameters.png" width="110%" style="display: block; margin: auto;" /&gt;

---
## Other relationships

* Individuals' expected rationality, `\(E[\lambda_i]\)`, correlates with number of successes ( `\(r \approx 0.84\)` )&lt;br&gt;&lt;br&gt;
* Uncertainty about partner's expectations decrease over time&lt;br&gt; ( `\(r \approx -0.55\)` between trial number and width of `\(P_i's \;\; 0.89\%\)` HPDI)&lt;br&gt;&lt;br&gt;
* Individual's beliefs diverge from population but grow closer to their partner's over time&lt;br&gt; ( `\(r \approx 0.56\)` and `\(r \approx -0.23\)`, measured as Kullback-Leibler divergence)&lt;br&gt;&lt;br&gt;
* Subject's own beliefs stabilize over time&lt;br&gt;( `\(r \approx -0.22\)` between trial number and KL divergence)&lt;br&gt;&lt;br&gt;
* Neither divergence from population belief nor width of the `\(P_i\)`'s HPDI are related to individuals' rates of success ( `\(r \approx 0.004\)` and `\(r \approx 0.02\)`)
---


## Predictions

&lt;img src="./ppc.png" width="110%" style="display: block; margin: auto;" /&gt;
---


## Accuracy
.large[
* `\(HM_{\lambda,\alpha,\beta}\)` has RMSE of `\(0.32\)`

* Always predicting short for frequent has RMSE of `\(0.63\)` (cf. Parikh 2000)

* Always predicting short for infrequent has RMSE of `\(0.78\)`

* Always avoiding it has RMSE of `\(0.67\)`
]

.footnote[
***
RMSE of best model reduces to `\(0.28\)` or `\(0.24\)` when excluding `\(4\)` or `\(8\)` worst-faring subjects
]
---


class: center

# Taking stock


---

## Narrower remarks

.large[
* Population-level trend is held up: short(er) patterns with more frequent
  * Rooted in expectations carried over from training
  
* Over time, individuals' established conventions of all flavors
  * frequent `\(\rightarrow\)` shorter
  * infrequent `\(\rightarrow\)` shorter
  * (in)frequent `\(\rightarrow\)` longer
  
* This is one possible explanation of Zipf's Law of Abbreviation, but
  * Link between dyads and population missing
  * In particular: neutral alternatives
]

---

## Broader remarks
1. Where possible and called for
  * model variation at multiple levels
  
  * make relationship between levels explicit 

--

2. Population-level trends can often hide individual-level variation, but the former ultimately draw from the latter.

--

3. Many individual-level patterns go against theoretical predictions (Zipf's Law of Abbreviation, Horn's division of pragmatic labor, Parikh's disambiguation model, ...). The reasons for this are likely manifold.

--

4. How dyadic-conventions find their way into the population is still a major and fascinating open question (cf. Hawkins et al. *forthcoming*)

--

5. Whether the association of the ambiguous form with the (in)frequent meaning is semantic or pragmatic in nature is another open question

---

class: center


# Thank you

Data: http://datashare.is.ed.ac.uk/handle/10283/2702&lt;br&gt;&lt;br&gt;
Code: https://osf.io/7m9np/&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

thomasbrochhagen@gmail.com&lt;br&gt;
https://brochhagen.github.io&lt;br&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightLines": true,
"highlightStyle": "github"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
